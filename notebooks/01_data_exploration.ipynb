{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMNIST Dataset Exploration\n",
    "\n",
    "This notebook explores the EMNIST ByClass dataset used for handwritten character recognition.\n",
    "\n",
    "**Dataset Information:**\n",
    "- **EMNIST ByClass**: 62 classes (digits 0-9, uppercase A-Z, lowercase a-z)\n",
    "- **Training samples**: ~697,932 images\n",
    "- **Test samples**: ~116,323 images\n",
    "- **Image size**: 28x28 grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our custom modules\n",
    "from src.data.dataset import load_emnist\n",
    "from src.utils.label_mapping import load_label_mapping\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "Load the EMNIST ByClass dataset using our custom loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "x_train, y_train, x_test, y_test = load_emnist()\n",
    "\n",
    "# Load label mapping\n",
    "label_mapping = load_label_mapping()\n",
    "\n",
    "print(f\"Training set shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test set shape: {x_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "print(f\"\\nNumber of classes: {len(np.unique(y_train))}\")\n",
    "print(f\"Image dimensions: {x_train.shape[1]}x{x_train.shape[2]}\")\n",
    "print(f\"Pixel value range: [{x_train.min()}, {x_train.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Images\n",
    "\n",
    "Display sample images from different character classes to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one sample from each class\n",
    "fig, axes = plt.subplots(8, 8, figsize=(16, 16))\n",
    "fig.suptitle('EMNIST ByClass - Sample Images (62 Classes)', fontsize=16, y=0.995)\n",
    "\n",
    "for class_idx in range(62):\n",
    "    # Find first occurrence of this class\n",
    "    sample_idx = np.where(y_train == class_idx)[0][0]\n",
    "    image = x_train[sample_idx]\n",
    "    character = label_mapping[class_idx]\n",
    "    \n",
    "    row = class_idx // 8\n",
    "    col = class_idx % 8\n",
    "    \n",
    "    if row < 8 and col < 8:\n",
    "        axes[row, col].imshow(image, cmap='gray')\n",
    "        axes[row, col].set_title(f\"'{character}' (idx:{class_idx})\", fontsize=10)\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "# Hide extra subplots\n",
    "for idx in range(62, 64):\n",
    "    row = idx // 8\n",
    "    col = idx % 8\n",
    "    if row < 8:\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Multiple Samples Per Class\n",
    "\n",
    "Show variations within each class (different handwriting styles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show multiple samples for selected classes\n",
    "selected_classes = [5, 10, 20, 36, 50, 61]  # '5', 'A', 'K', 'a', 'o', 'z'\n",
    "samples_per_class = 10\n",
    "\n",
    "fig, axes = plt.subplots(len(selected_classes), samples_per_class, figsize=(15, 10))\n",
    "fig.suptitle('Handwriting Variations Across Different Classes', fontsize=14)\n",
    "\n",
    "for i, class_idx in enumerate(selected_classes):\n",
    "    # Get indices for this class\n",
    "    class_indices = np.where(y_train == class_idx)[0]\n",
    "    # Randomly sample\n",
    "    sample_indices = np.random.choice(class_indices, samples_per_class, replace=False)\n",
    "    \n",
    "    character = label_mapping[class_idx]\n",
    "    \n",
    "    for j, sample_idx in enumerate(sample_indices):\n",
    "        axes[i, j].imshow(x_train[sample_idx], cmap='gray')\n",
    "        axes[i, j].axis('off')\n",
    "        \n",
    "        if j == 0:\n",
    "            axes[i, j].set_ylabel(f\"'{character}'\", fontsize=12, rotation=0, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Class Distribution Analysis\n",
    "\n",
    "Analyze how many samples exist for each character class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count samples per class\n",
    "unique_labels, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Create character labels for the plot\n",
    "character_labels = [label_mapping[label] for label in unique_labels]\n",
    "\n",
    "# Plot distribution\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "bars = ax.bar(range(len(counts)), counts, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "\n",
    "# Color code by category\n",
    "for i, label in enumerate(unique_labels):\n",
    "    if label < 10:  # Digits\n",
    "        bars[i].set_color('salmon')\n",
    "    elif label < 36:  # Uppercase\n",
    "        bars[i].set_color('lightgreen')\n",
    "    else:  # Lowercase\n",
    "        bars[i].set_color('lightblue')\n",
    "\n",
    "ax.set_xlabel('Character Class', fontsize=12)\n",
    "ax.set_ylabel('Number of Samples', fontsize=12)\n",
    "ax.set_title('EMNIST ByClass - Sample Distribution', fontsize=14, pad=20)\n",
    "ax.set_xticks(range(len(counts)))\n",
    "ax.set_xticklabels(character_labels, rotation=45, ha='right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='salmon', label='Digits (0-9)'),\n",
    "    Patch(facecolor='lightgreen', label='Uppercase (A-Z)'),\n",
    "    Patch(facecolor='lightblue', label='Lowercase (a-z)')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Class Distribution Statistics:\")\n",
    "print(f\"  Mean samples per class: {counts.mean():.0f}\")\n",
    "print(f\"  Std deviation: {counts.std():.0f}\")\n",
    "print(f\"  Min samples: {counts.min():,} (class '{label_mapping[unique_labels[counts.argmin()]]}')\")\n",
    "print(f\"  Max samples: {counts.max():,} (class '{label_mapping[unique_labels[counts.argmax()]]}')\")\n",
    "print(f\"  Imbalance ratio: {counts.max() / counts.min():.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pixel Intensity Distribution\n",
    "\n",
    "Analyze the distribution of pixel values across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a subset for faster computation\n",
    "sample_size = 10000\n",
    "sample_indices = np.random.choice(len(x_train), sample_size, replace=False)\n",
    "sample_images = x_train[sample_indices]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram of pixel values\n",
    "axes[0].hist(sample_images.flatten(), bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Pixel Value', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Pixel Values', fontsize=14)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Average pixel intensity per image\n",
    "avg_intensities = sample_images.mean(axis=(1, 2))\n",
    "axes[1].hist(avg_intensities, bins=50, color='coral', edgecolor='darkred', alpha=0.7)\n",
    "axes[1].set_xlabel('Average Pixel Intensity per Image', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Distribution of Average Image Intensities', fontsize=14)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Pixel Value Statistics (from {sample_size:,} sampled images):\")\n",
    "print(f\"  Global mean: {sample_images.mean():.2f}\")\n",
    "print(f\"  Global std: {sample_images.std():.2f}\")\n",
    "print(f\"  Min value: {sample_images.min()}\")\n",
    "print(f\"  Max value: {sample_images.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Check\n",
    "\n",
    "Check for potential issues like completely black/white images or outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for completely black or white images\n",
    "black_images = np.sum(x_train.max(axis=(1, 2)) == 0)\n",
    "white_images = np.sum(x_train.min(axis=(1, 2)) == 255)\n",
    "low_variance = np.sum(x_train.std(axis=(1, 2)) < 5)\n",
    "\n",
    "print(\"Data Quality Check:\")\n",
    "print(f\"  Total training images: {len(x_train):,}\")\n",
    "print(f\"  Completely black images: {black_images:,}\")\n",
    "print(f\"  Completely white images: {white_images:,}\")\n",
    "print(f\"  Low variance images (std < 5): {low_variance:,} ({100*low_variance/len(x_train):.2f}%)\")\n",
    "\n",
    "# Check label coverage\n",
    "missing_labels = set(range(62)) - set(np.unique(y_train))\n",
    "if missing_labels:\n",
    "    print(f\"  ⚠ Missing labels: {missing_labels}\")\n",
    "else:\n",
    "    print(f\"  ✓ All 62 classes are represented\")\n",
    "\n",
    "# Sample some low variance images to visualize\n",
    "if low_variance > 0:\n",
    "    low_var_indices = np.where(x_train.std(axis=(1, 2)) < 5)[0][:5]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, min(5, len(low_var_indices)), figsize=(15, 3))\n",
    "    fig.suptitle('Examples of Low Variance Images', fontsize=12)\n",
    "    \n",
    "    for i, idx in enumerate(low_var_indices):\n",
    "        if len(low_var_indices) > 1:\n",
    "            ax = axes[i]\n",
    "        else:\n",
    "            ax = axes\n",
    "        ax.imshow(x_train[idx], cmap='gray')\n",
    "        ax.set_title(f\"Var: {x_train[idx].std():.2f}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Findings and Observations\n",
    "\n",
    "### Summary:\n",
    "\n",
    "1. **Dataset Size**: \n",
    "   - Training: 697,932 images\n",
    "   - Test: 116,323 images\n",
    "   - Total: 814,255 images\n",
    "\n",
    "2. **Image Properties**:\n",
    "   - Dimensions: 28x28 pixels (grayscale)\n",
    "   - Pixel values: 0-255 (uint8)\n",
    "   - Generally good contrast with characters\n",
    "\n",
    "3. **Class Distribution**:\n",
    "   - 62 classes total (10 digits + 26 uppercase + 26 lowercase)\n",
    "   - Imbalanced distribution (some classes have 20x more samples than others)\n",
    "   - May need to consider class weights during training\n",
    "\n",
    "4. **Data Quality**:\n",
    "   - Very few completely black/white images\n",
    "   - Most images have sufficient variance (visible characters)\n",
    "   - All 62 classes are represented\n",
    "\n",
    "5. **Recommendations for Model Training**:\n",
    "   - **Normalization**: Scale pixel values to [0, 1] range\n",
    "   - **Class Imbalance**: Consider using class weights or data augmentation\n",
    "   - **Data Augmentation**: Apply rotation, shift, zoom to increase robustness\n",
    "   - **Validation Split**: Use 15% of training data for validation\n",
    "   - **Target Accuracy**: Aim for ≥85% given the dataset size and quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
