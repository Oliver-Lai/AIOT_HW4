{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23882821",
   "metadata": {},
   "source": [
    "# EMNIST Data Preprocessing Pipeline\n",
    "\n",
    "This notebook demonstrates the complete data preprocessing pipeline for the EMNIST character recognition system.\n",
    "\n",
    "**Key Operations:**\n",
    "1. **Normalization**: Scale pixel values from [0, 255] to [0, 1]\n",
    "2. **Reshaping**: Add channel dimension for CNN input\n",
    "3. **One-Hot Encoding**: Convert labels to categorical format\n",
    "4. **Train/Validation Split**: 85/15 split with stratification\n",
    "5. **Data Augmentation**: Rotation, shifts, and zoom transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e8c26",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our custom modules\n",
    "from src.data.dataset import load_emnist\n",
    "from src.utils.label_mapping import load_label_mapping\n",
    "from src.preprocessing.preprocessing import (\n",
    "    normalize_images,\n",
    "    reshape_images,\n",
    "    one_hot_encode_labels,\n",
    "    preprocess_data,\n",
    "    create_train_val_split,\n",
    "    create_data_augmentation_generator,\n",
    "    visualize_augmentation\n",
    ")\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")\n",
    "\n",
    "# Load the dataset\n",
    "print(\"\\nLoading EMNIST ByClass dataset...\")\n",
    "x_train, y_train, x_test, y_test = load_emnist()\n",
    "label_mapping = load_label_mapping()\n",
    "\n",
    "print(f\"âœ“ Dataset loaded:\")\n",
    "print(f\"  Training: {x_train.shape[0]:,} samples\")\n",
    "print(f\"  Test: {x_test.shape[0]:,} samples\")\n",
    "print(f\"  Image size: {x_train.shape[1]}x{x_train.shape[2]}\")\n",
    "print(f\"  Classes: {len(np.unique(y_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1a56c",
   "metadata": {},
   "source": [
    "## 2. Normalization\n",
    "\n",
    "Normalize pixel values from [0, 255] to [0, 1] for better neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34884c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "x_train_norm = normalize_images(x_train)\n",
    "x_test_norm = normalize_images(x_test)\n",
    "\n",
    "print(\"Before normalization:\")\n",
    "print(f\"  Data type: {x_train.dtype}\")\n",
    "print(f\"  Value range: [{x_train.min()}, {x_train.max()}]\")\n",
    "print(f\"  Mean: {x_train.mean():.2f}\")\n",
    "print(f\"  Std: {x_train.std():.2f}\")\n",
    "\n",
    "print(\"\\nAfter normalization:\")\n",
    "print(f\"  Data type: {x_train_norm.dtype}\")\n",
    "print(f\"  Value range: [{x_train_norm.min():.4f}, {x_train_norm.max():.4f}]\")\n",
    "print(f\"  Mean: {x_train_norm.mean():.4f}\")\n",
    "print(f\"  Std: {x_train_norm.std():.4f}\")\n",
    "\n",
    "# Visualize the effect\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Original\n",
    "axes[0].imshow(x_train[0], cmap='gray', vmin=0, vmax=255)\n",
    "axes[0].set_title(f\"Original (range: [0, 255])\\nCharacter: '{label_mapping[y_train[0]]}'\", fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Normalized\n",
    "axes[1].imshow(x_train_norm[0], cmap='gray', vmin=0, vmax=1)\n",
    "axes[1].set_title(f\"Normalized (range: [0, 1])\\nCharacter: '{label_mapping[y_train[0]]}'\", fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Normalization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec9113",
   "metadata": {},
   "source": [
    "## 3. Reshaping\n",
    "\n",
    "Add channel dimension to images for CNN input (n_samples, height, width, channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e83d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to add channel dimension\n",
    "x_train_reshaped = reshape_images(x_train_norm)\n",
    "x_test_reshaped = reshape_images(x_test_norm)\n",
    "\n",
    "print(\"Before reshaping:\")\n",
    "print(f\"  Training shape: {x_train_norm.shape}\")\n",
    "print(f\"  Test shape: {x_test_norm.shape}\")\n",
    "\n",
    "print(\"\\nAfter reshaping:\")\n",
    "print(f\"  Training shape: {x_train_reshaped.shape}\")\n",
    "print(f\"  Test shape: {x_test_reshaped.shape}\")\n",
    "\n",
    "print(\"\\nâœ“ Reshaping complete - ready for CNN input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3720f",
   "metadata": {},
   "source": [
    "## 4. One-Hot Encoding\n",
    "\n",
    "Convert integer labels to categorical one-hot encoded vectors for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977858bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "y_train_encoded = one_hot_encode_labels(y_train, num_classes=62)\n",
    "y_test_encoded = one_hot_encode_labels(y_test, num_classes=62)\n",
    "\n",
    "print(\"Before one-hot encoding:\")\n",
    "print(f\"  Training labels shape: {y_train.shape}\")\n",
    "print(f\"  Test labels shape: {y_test.shape}\")\n",
    "print(f\"  Sample label: {y_train[0]} (character '{label_mapping[y_train[0]]}')\")\n",
    "\n",
    "print(\"\\nAfter one-hot encoding:\")\n",
    "print(f\"  Training labels shape: {y_train_encoded.shape}\")\n",
    "print(f\"  Test labels shape: {y_test_encoded.shape}\")\n",
    "print(f\"  Sample encoded label shape: {y_train_encoded[0].shape}\")\n",
    "print(f\"  Sum of encoded vector: {y_train_encoded[0].sum()}\")\n",
    "\n",
    "# Visualize one-hot encoding\n",
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "sample_idx = 0\n",
    "sample_label = y_train[sample_idx]\n",
    "sample_encoded = y_train_encoded[sample_idx]\n",
    "\n",
    "ax.bar(range(62), sample_encoded, color='steelblue', edgecolor='navy', alpha=0.7)\n",
    "ax.axvline(sample_label, color='red', linestyle='--', linewidth=2, label=f\"Class {sample_label} ('{label_mapping[sample_label]}')\")\n",
    "ax.set_xlabel('Class Index', fontsize=12)\n",
    "ax.set_ylabel('Value', fontsize=12)\n",
    "ax.set_title(f\"One-Hot Encoding Example - Character '{label_mapping[sample_label]}'\", fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ One-hot encoding complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a1e1f",
   "metadata": {},
   "source": [
    "## 5. Train/Validation Split\n",
    "\n",
    "Split the training data into 85% training and 15% validation with stratification to maintain class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validation split (85/15)\n",
    "x_train_split, x_val, y_train_split, y_val = create_train_val_split(\n",
    "    x_train_reshaped,\n",
    "    y_train_encoded,\n",
    "    val_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=True\n",
    ")\n",
    "\n",
    "print(\"Dataset split:\")\n",
    "print(f\"  Original training: {x_train_reshaped.shape[0]:,} samples\")\n",
    "print(f\"  New training: {x_train_split.shape[0]:,} samples ({x_train_split.shape[0]/x_train_reshaped.shape[0]*100:.1f}%)\")\n",
    "print(f\"  Validation: {x_val.shape[0]:,} samples ({x_val.shape[0]/x_train_reshaped.shape[0]*100:.1f}%)\")\n",
    "print(f\"  Test: {x_test_reshaped.shape[0]:,} samples\")\n",
    "\n",
    "# Verify class distribution is maintained\n",
    "y_train_classes = np.argmax(y_train_split, axis=1)\n",
    "y_val_classes = np.argmax(y_val, axis=1)\n",
    "\n",
    "train_dist = np.bincount(y_train_classes, minlength=62) / len(y_train_classes)\n",
    "val_dist = np.bincount(y_val_classes, minlength=62) / len(y_val_classes)\n",
    "\n",
    "# Plot class distributions\n",
    "fig, axes = plt.subplots(2, 1, figsize=(18, 8))\n",
    "\n",
    "axes[0].bar(range(62), train_dist, color='skyblue', alpha=0.7, label='Training Set')\n",
    "axes[0].set_ylabel('Proportion', fontsize=11)\n",
    "axes[0].set_title('Class Distribution - Training Set', fontsize=13)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].bar(range(62), val_dist, color='coral', alpha=0.7, label='Validation Set')\n",
    "axes[1].set_xlabel('Class Index', fontsize=11)\n",
    "axes[1].set_ylabel('Proportion', fontsize=11)\n",
    "axes[1].set_title('Class Distribution - Validation Set', fontsize=13)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation between distributions\n",
    "correlation = np.corrcoef(train_dist, val_dist)[0, 1]\n",
    "print(f\"\\nClass distribution correlation: {correlation:.4f}\")\n",
    "print(\"âœ“ Train/validation split complete - distributions are balanced\" if correlation > 0.99 else \"âš  Warning: distributions may be imbalanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e309af4",
   "metadata": {},
   "source": [
    "## 6. Data Augmentation\n",
    "\n",
    "Configure and demonstrate data augmentation with rotation (Â±15Â°), shifts (Â±10%), and zoom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df84e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data augmentation generator\n",
    "datagen = create_data_augmentation_generator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "print(\"Data Augmentation Configuration:\")\n",
    "print(\"  Rotation range: Â±15Â°\")\n",
    "print(\"  Width shift range: Â±10%\")\n",
    "print(\"  Height shift range: Â±10%\")\n",
    "print(\"  Zoom range: Â±10%\")\n",
    "print(\"  Fill mode: nearest\")\n",
    "\n",
    "# Visualize augmentation on sample images\n",
    "sample_indices = [0, 100, 200]  # Different character samples\n",
    "num_augmented = 9\n",
    "\n",
    "fig, axes = plt.subplots(len(sample_indices), num_augmented + 1, figsize=(20, 3 * len(sample_indices)))\n",
    "fig.suptitle('Data Augmentation Examples', fontsize=16, y=0.98)\n",
    "\n",
    "for row_idx, sample_idx in enumerate(sample_indices):\n",
    "    original_image = x_train_split[sample_idx]\n",
    "    character = label_mapping[np.argmax(y_train_split[sample_idx])]\n",
    "    \n",
    "    # Show original\n",
    "    axes[row_idx, 0].imshow(original_image[:, :, 0], cmap='gray')\n",
    "    axes[row_idx, 0].set_title(f\"Original\\n'{character}'\", fontsize=11)\n",
    "    axes[row_idx, 0].axis('off')\n",
    "    axes[row_idx, 0].set_facecolor('#f0f0f0')\n",
    "    \n",
    "    # Generate and show augmented samples\n",
    "    augmented_samples = visualize_augmentation(original_image, datagen, num_samples=num_augmented)\n",
    "    \n",
    "    for col_idx, aug_image in enumerate(augmented_samples):\n",
    "        axes[row_idx, col_idx + 1].imshow(aug_image[:, :, 0], cmap='gray')\n",
    "        axes[row_idx, col_idx + 1].set_title(f\"Aug {col_idx + 1}\", fontsize=10)\n",
    "        axes[row_idx, col_idx + 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Data augmentation configured and visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a087ea",
   "metadata": {},
   "source": [
    "## 7. Validation of Augmented Data\n",
    "\n",
    "Verify that augmented images maintain valid pixel ranges and shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a batch of augmented data for validation\n",
    "sample_batch_size = 100\n",
    "sample_batch = x_train_split[:sample_batch_size]\n",
    "\n",
    "augmented_batch = []\n",
    "for batch in datagen.flow(sample_batch, batch_size=sample_batch_size, shuffle=False):\n",
    "    augmented_batch.append(batch)\n",
    "    break  # Only need one batch\n",
    "\n",
    "augmented_batch = augmented_batch[0]\n",
    "\n",
    "print(\"Augmented Data Validation:\")\n",
    "print(f\"  Batch size: {augmented_batch.shape[0]}\")\n",
    "print(f\"  Image shape: {augmented_batch.shape[1:]}\")\n",
    "print(f\"  Pixel value range: [{augmented_batch.min():.4f}, {augmented_batch.max():.4f}]\")\n",
    "print(f\"  Mean: {augmented_batch.mean():.4f}\")\n",
    "print(f\"  Std: {augmented_batch.std():.4f}\")\n",
    "\n",
    "# Check for any invalid values\n",
    "has_nan = np.isnan(augmented_batch).any()\n",
    "has_inf = np.isinf(augmented_batch).any()\n",
    "in_valid_range = (augmented_batch.min() >= 0.0) and (augmented_batch.max() <= 1.0)\n",
    "\n",
    "print(f\"\\nData Quality Checks:\")\n",
    "print(f\"  Contains NaN: {has_nan}\")\n",
    "print(f\"  Contains Inf: {has_inf}\")\n",
    "print(f\"  Pixels in [0, 1]: {in_valid_range}\")\n",
    "\n",
    "if not has_nan and not has_inf and in_valid_range:\n",
    "    print(\"\\nâœ“ All augmented data is valid!\")\n",
    "else:\n",
    "    print(\"\\nâš  Warning: Augmented data may have issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e8b97",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "### Preprocessing Pipeline Summary:\n",
    "\n",
    "1. âœ… **Normalization**: Scaled pixel values from [0, 255] to [0, 1]\n",
    "2. âœ… **Reshaping**: Added channel dimension (28, 28) â†’ (28, 28, 1)\n",
    "3. âœ… **One-Hot Encoding**: Converted labels to 62-class categorical vectors\n",
    "4. âœ… **Train/Val Split**: Created 85/15 split with stratification\n",
    "5. âœ… **Data Augmentation**: Configured rotation (Â±15Â°), shifts (Â±10%), zoom (Â±10%)\n",
    "\n",
    "### Final Dataset Shapes:\n",
    "\n",
    "- **Training Set**: {:,} samples\n",
    "- **Validation Set**: {:,} samples\n",
    "- **Test Set**: {:,} samples\n",
    "\n",
    "### Key Statistics:\n",
    "\n",
    "- **Pixel Value Range**: [0.0, 1.0] âœ“\n",
    "- **Image Shape**: (28, 28, 1) âœ“\n",
    "- **Label Shape**: (62,) one-hot encoded âœ“\n",
    "- **Class Distribution**: Balanced across train/val splits âœ“\n",
    "- **Augmented Data**: All transformations produce valid images âœ“\n",
    "\n",
    "### Next Phase: Model Development\n",
    "\n",
    "The preprocessing pipeline is complete. Data is ready for:\n",
    "- CNN model architecture design\n",
    "- Model training with data augmentation\n",
    "- Performance evaluation on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final statistics\n",
    "print(\"=\"*60)\n",
    "print(\"PREPROCESSING PIPELINE COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nðŸ“Š Final Dataset Shapes:\")\n",
    "print(f\"   Training:   {x_train_split.shape[0]:>8,} samples â†’ {x_train_split.shape}\")\n",
    "print(f\"   Validation: {x_val.shape[0]:>8,} samples â†’ {x_val.shape}\")\n",
    "print(f\"   Test:       {x_test_reshaped.shape[0]:>8,} samples â†’ {x_test_reshaped.shape}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Label Shapes:\")\n",
    "print(f\"   Training labels:   {y_train_split.shape}\")\n",
    "print(f\"   Validation labels: {y_val.shape}\")\n",
    "print(f\"   Test labels:       {y_test_encoded.shape}\")\n",
    "\n",
    "print(f\"\\nâœ… Data Quality:\")\n",
    "print(f\"   Pixel range:       [{x_train_split.min():.4f}, {x_train_split.max():.4f}]\")\n",
    "print(f\"   Mean pixel value:  {x_train_split.mean():.4f}\")\n",
    "print(f\"   No NaN values:     {not np.isnan(x_train_split).any()}\")\n",
    "print(f\"   No Inf values:     {not np.isinf(x_train_split).any()}\")\n",
    "\n",
    "print(f\"\\nðŸ”„ Augmentation Ready:\")\n",
    "print(f\"   Generator configured: âœ“\")\n",
    "print(f\"   Rotation: Â±15Â°\")\n",
    "print(f\"   Shifts: Â±10%\")\n",
    "print(f\"   Zoom: Â±10%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Ready for Phase 4: Model Development\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
